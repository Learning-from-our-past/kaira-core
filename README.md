# ![alt text](http://i.imgur.com/vBIAv3m.png "Kaira logo") Kaira-core

Main module containing logic for data extraction and command line interface.

## Dependencies

- Python 3

## Setup

### Nix

If you use Nix, then you can install most dependencies easily with [`nix-direnv`](https://github.com/nix-community/nix-direnv). Then you just need to do the `venv`/`pip` installation steps below.

### No Nix

The codebase has been formatted with `black` and reformatted for compliance with PEP8. The reformattings resulted in two commits that changed a lot of lines, which in turn can make it unnecessarily challenging to use `git blame` (and `blame` integration in IDEs) to peek into the history of the project. However, there is a way around this challenge: the hashes of the reformatting commits are in `.git-blame-ignore-revs`. To configure `git` to use that file when using `git blame`: `git config blame.ignoreRevsFile .git-blame-ignore-revs`.

```
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
cp scripts/pre-commit .git/hooks
```

If you wish to chunk the html files with duplicate filtering, you will also need ssdeep. Installation of ssdeep is
done through pip, but you also need to install ssdeep on your system, which can be done with apt:

```
sudo apt-get install ssdeep libfuzzy-dev libffi-dev python3-dev
```

More on ssdeep installation can be found [here](http://python-ssdeep.readthedocs.io/en/latest/installation.html)

If you need to generate the XML files with the CoNLLU/NLP data, you will need to perform the nlp-setup step:
**NB:** NLP setup is very outdated as of 2022-08. It is due to be redone/updated. This notice will be removed when it is.

```
inv nlp-setup  # NOTE: you need to have Java (eg. openjdk) installed for this to work
```

Note that ssdeep pip-package seems to be difficult to install on MacOS since it was tested
only on Linux systems according to their documentation. Ignore the dependency on MacOS
and install other packages from `requirements.txt`. Everything else than chunking and
duplicating code will work and affected tests are skipped when ssdeep is not available.

## Setup with Docker

It is possible to run Kaira inside a Docker container, in which case you may be able to take significant
shortcuts in getting the development environment set up. Please be awarethat running the extraction inside
a container is noticeably slower than not running it in a container. Preliminary tests suggest that
extraction takes approximately 66% more time to finish when done inside a container.

These instructions are written for Linux (Ubuntu 18.04). Using them for macOS should be very straightforward,
but following them on Windows may require some interpretation and improvisation.

1. `docker build -t kaira .`
2. `docker run -d -v $(pwd):/app --name docker-kaira kaira:latest`
   - Your shell should substitute `$(pwd)` with the current working directory, i.e. the Kaira project
     root directory. If not (**Windows users?**), fix it with the correct syntax or do the substitution by hand.

Now your Dockerized Kaira environment should be ready to go. You'll be able to run any and all of Kaira's
invoke tasks using the following command:

`docker exec docker-kaira <command here>`

e.g. `docker exec docker-kaira invoke -l` will show you a list of all the invoke tasks. `docker exec
docker-kaira invoke test` will run tests.
`docker exec docker-kaira invoke extract -b material/siirtokarjalisten_tie_I.xml` will run extraction on the
first book.

For ease of use, you will probably want to create some sort of script or task files that will allow you
tu run these commands more easily. `.bat` files might be a convenient choice Windows users.

# Attribution

Please cite if you use this software or datasets generated by it in your research:

> T. Salmi, L. Kallioniemi, J. Loehr. Kaira-core [computer software]. Lammi Biological Station 2022
> Available at https://github.com/Tumetsu/Kaira
